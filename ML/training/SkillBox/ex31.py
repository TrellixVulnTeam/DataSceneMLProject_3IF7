# Постановка ML задачи линейной регрессии

from numpy.linalg import inv
from matplotlib import pyplot as plt
import numpy as np


plt.scatter([50, 60, 70, 100], [10, 30, 40, 50], 40, 'g', 'o', alpha=0.8)
plt.show()


X = np.array([[1, 50],[1, 60],[1, 70],[1, 100]])
print(X)

Y = np.array([[10],[30],[40],[50]])
print(Y)

# Выписываем формулу по кусочкам. Сначала перемножим матрицу объекты-признаки саму на себя XT⋅X
X_T_X = (X.T).dot(X)
print(X_T_X)

# Теперь найдём обратную матрицу к ней.
# Тут вручную прогграммировать ничего не надо - для нахождения обратной матрицы уже есть готовая реализация


X_T_X_inverted = inv(X_T_X)
print(X_T_X_inverted)

w = X_T_X_inverted.dot(X.T).dot(Y)
print("w_1=%.5f, w_2=%.3f" % (w[0][0],w[1][0]))

# То есть наш набор из пяти точек прекрасно описывает прямая линия с уравнением  y=−17.5+0.714⋅x . Давайте проверим это графически.


# задаём границы координатных осей
margin = 10
X_min = 20
X_max = X[:,1].max()+margin

# набор точек, чтобы нарисовать прямую
X_support = np.linspace(X_min, X_max, num=100)
# предсказания нашей модели
Y_model = w[0][0] + w[1][0]*X_support

# Исходные данные подготовлены! Осталось нарисовать график

# настройка графика
plt.xlim(X_min, X_max)
plt.ylim(0, Y[:,0].max() + margin)
# рисуем исходные точки
plt.scatter(X[:,1], Y[:,0], 40, 'g', 'o', alpha=0.8)
# предсказания модели
plt.plot(X_support, Y_model)

plt.show()

"""
Готово! Получилось очень круто – на входе у нас только несколько точек и математическая формула. 
Подставляем наши точки в формулу – ничего себе, теперь мы можем предсказывать цену дома по его площади.
Обучение модели линейной регрессии сводится (в двумерном случае) к вычислению коэффициентов  a  и  b  таким образом, 
чтобы линия регрессии лежала ровно в центре нашего облака точек (пример – зависимость объёмов продаже мороженного от температуры воздуха)

"""




